{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomassalcedas/dataeng/blob/main/spark/examples/05-aggregations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y331t1OSI1s"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucprosa/dataeng-basic-course/blob/main/spark/examples/05-aggregations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kQUWb3uCp6Xq",
        "outputId": "19f072cf-b353-46da-afdd-41cb8a980171",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOA_wQSmLd9z"
      },
      "source": [
        "# Aggregations\n",
        "- Group By\n",
        "- Windows Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9LeYFsPTjAb"
      },
      "source": [
        "# Setting up PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uYXeODL0T1fO",
        "outputId": "a1cefa41-f873-4b55-c744-12ae48c5ec04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "637HFw00T3LP"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master('local').appName('Spark Course').config('spark.ui.port', '4050').getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLiYPwuJSI1w"
      },
      "source": [
        "# Aggregations\n",
        "\n",
        "https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#aggregate-functions\n",
        "\n",
        "https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-aggregate.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GPdtlX5BSI1w",
        "outputId": "b178ba6f-cb45-4133-b347-302ba50e4ec2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------+------+\n",
            "|    employee_name|department|salary|\n",
            "+-----------------+----------+------+\n",
            "|     Diane Murphy|Accounting|  8435|\n",
            "|   Mary Patterson|Accounting|  9998|\n",
            "|    Jeff Firrelli|Accounting|  8992|\n",
            "|William Patterson|Accounting|  8870|\n",
            "|    Gerard Bondur|Accounting| 11472|\n",
            "|      Anthony Bow|Accounting|  6627|\n",
            "|  Leslie Jennings|        IT|  8113|\n",
            "|  Leslie Thompson|        IT|  5186|\n",
            "|   Julie Firrelli|     Sales|  9181|\n",
            "|  Steve Patterson|     Sales|  9441|\n",
            "|   Foon Yue Tseng|     Sales|  6660|\n",
            "|    George Vanauf|     Sales| 10563|\n",
            "|      Loui Bondur|       SCM| 10449|\n",
            "| Gerard Hernandez|       SCM|  6949|\n",
            "|  Pamela Castillo|       SCM| 11303|\n",
            "|       Larry Bott|       SCM| 11798|\n",
            "|      Barry Jones|       SCM| 10586|\n",
            "+-----------------+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sql_query = \"\"\"CREATE OR REPLACE TEMPORARY VIEW basic_pays AS SELECT * FROM VALUES\n",
        "('Diane Murphy','Accounting',8435),\n",
        "('Mary Patterson','Accounting',9998),\n",
        "('Jeff Firrelli','Accounting',8992),\n",
        "('William Patterson','Accounting',8870),\n",
        "('Gerard Bondur','Accounting',11472),\n",
        "('Anthony Bow','Accounting',6627),\n",
        "('Leslie Jennings','IT',8113),\n",
        "('Leslie Thompson','IT',5186),\n",
        "('Julie Firrelli','Sales',9181),\n",
        "('Steve Patterson','Sales',9441),\n",
        "('Foon Yue Tseng','Sales',6660),\n",
        "('George Vanauf','Sales',10563),\n",
        "('Loui Bondur','SCM',10449),\n",
        "('Gerard Hernandez','SCM',6949),\n",
        "('Pamela Castillo','SCM',11303),\n",
        "('Larry Bott','SCM',11798),\n",
        "('Barry Jones','SCM',10586)\n",
        "AS basic_pays(employee_name, department, salary)\"\"\"\n",
        "\n",
        "# creating temp view\n",
        "spark.sql(sql_query)\n",
        "\n",
        "df = spark.table(\"basic_pays\")\n",
        "df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perc_query = \"\"\"SELECT\n",
        "    department,\n",
        "    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary) AS pc1,\n",
        "    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary) FILTER (WHERE employee_name LIKE '%Bo%') AS pc2,\n",
        "    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary DESC) AS pc3,\n",
        "    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary DESC) FILTER (WHERE employee_name LIKE '%Bo%') AS pc4,\n",
        "    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary) AS pd1,\n",
        "    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary) FILTER (WHERE employee_name LIKE '%Bo%') AS pd2,\n",
        "    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary DESC) AS pd3,\n",
        "    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary DESC) FILTER (WHERE employee_name LIKE '%Bo%') AS pd4\n",
        "FROM basic_pays\n",
        "GROUP BY department\n",
        "ORDER BY department;\"\"\"\n",
        "\n",
        "spark.sql(perc_query).show()"
      ],
      "metadata": {
        "id": "Aa38HFEQVSM9",
        "outputId": "1fee5726-2c55-4ca0-be73-a328d8fdb1f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+--------+-------+--------+-------+-------+-------+-------+\n",
            "|department|    pc1|     pc2|    pc3|     pc4|    pd1|    pd2|    pd3|    pd4|\n",
            "+----------+-------+--------+-------+--------+-------+-------+-------+-------+\n",
            "|Accounting|8543.75| 7838.25| 9746.5|10260.75| 8435.0| 6627.0| 9998.0|11472.0|\n",
            "|        IT|5917.75|    NULL|7381.25|    NULL| 5186.0|   NULL| 8113.0|   NULL|\n",
            "|       SCM|10449.0|10786.25|11303.0|11460.75|10449.0|10449.0|11303.0|11798.0|\n",
            "|     Sales|8550.75|    NULL| 9721.5|    NULL| 6660.0|   NULL|10563.0|   NULL|\n",
            "+----------+-------+--------+-------+--------+-------+-------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "(df\n",
        " .groupBy(\"department\")\n",
        " .agg(sum(\"salary\").alias(\"sum_salary\"),\n",
        "      round(avg(\"salary\"),2).alias(\"avg_salary\"),\n",
        "      min(\"salary\").alias(\"min_salary\"),\n",
        "      array_agg(\"employee_name\").alias(\"employees\"),\n",
        "      count(lit(\"\")).alias(\"count_employees\"))\n",
        " .filter(col(\"count_employees\") > 2)\n",
        " .show(10, False))"
      ],
      "metadata": {
        "id": "ZbfHHI_wYJge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question"
      ],
      "metadata": {
        "id": "HQjSVZgFbiUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1\n",
        "# Aggregate data by surname\n",
        "# Calculate highest salary by surname\n",
        "# Include the respective employee that has the highest salary\n",
        "# Include department information about this employee\n",
        "# Count how many employees has that surname\n",
        "# Put in an array all the first_names of the respective surname ordered\n",
        "\n",
        "\n",
        "# schema expected:\n",
        "# surname | count_employees | highest_salary | employee_with_highest_salary | department_with_highest_salary | array_with_all_the_first_names |"
      ],
      "metadata": {
        "id": "sAB_dzZabf_o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}