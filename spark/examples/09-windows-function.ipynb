{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomassalcedas/dataeng/blob/main/spark/examples/09-windows-function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOA_wQSmLd9z"
      },
      "source": [
        "# Windows Function\n",
        "- Window functions operate on a group of rows, referred to as a window, and calculate a return value for each row based on the group of rows.\n",
        "- Window functions are useful for processing tasks such as calculating a moving average, computing a cumulative statistic, or accessing the value of rows given the relative position of the current row."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9LeYFsPTjAb"
      },
      "source": [
        "# Setting up PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uYXeODL0T1fO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f289a91f-ec44-4d6d-d2e4-0293e4181287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBf-CZ-cmugR",
        "outputId": "fc364f2e-bc5f-41bf-b55e-f9868b5e5aef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "637HFw00T3LP"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master('local').appName('Spark Course').config('spark.ui.port', '4050').getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BRgjNQbOKE0"
      },
      "source": [
        "# Windows Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fZzWrJbROKE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec0aa13e-e7b3-4955-82a7-cecdc33cef2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+------+---+\n",
            "| name|       dept|salary|age|\n",
            "+-----+-----------+------+---+\n",
            "| Lisa|      Sales| 10000| 35|\n",
            "| Evan|      Sales| 32000| 38|\n",
            "| Fred|Engineering| 21000| 28|\n",
            "| Alex|      Sales| 30000| 33|\n",
            "|  Tom|Engineering| 23000| 33|\n",
            "| Jane|  Marketing| 29000| 28|\n",
            "| Jeff|  Marketing| 35000| 38|\n",
            "| Paul|Engineering| 29000| 23|\n",
            "|Chloe|Engineering| 23000| 25|\n",
            "+-----+-----------+------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# using inline table to prepare the data\n",
        "\n",
        "qry = \"\"\"CREATE OR REPLACE TEMPORARY VIEW employees AS SELECT * FROM VALUES(\"Lisa\", \"Sales\", 10000, 35),\n",
        "(\"Evan\", \"Sales\", 32000, 38),\n",
        "(\"Fred\", \"Engineering\", 21000, 28),\n",
        "(\"Alex\", \"Sales\", 30000, 33),\n",
        "(\"Tom\", \"Engineering\", 23000, 33),\n",
        "(\"Jane\", \"Marketing\", 29000, 28),\n",
        "(\"Jeff\", \"Marketing\", 35000, 38),\n",
        "(\"Paul\", \"Engineering\", 29000, 23),\n",
        "(\"Chloe\", \"Engineering\", 23000, 25)\n",
        "AS employees(name, dept, salary, age)\"\"\"\n",
        "\n",
        "spark.sql(qry)\n",
        "spark.table(\"employees\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "o0JtIU70Pgoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa3a9748-92d2-44ee-f3b5-3a69edb9b078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+------+----------+\n",
            "| name|       dept|salary|dense_rank|\n",
            "+-----+-----------+------+----------+\n",
            "| Fred|Engineering| 21000|         1|\n",
            "|  Tom|Engineering| 23000|         2|\n",
            "|Chloe|Engineering| 23000|         2|\n",
            "| Paul|Engineering| 29000|         3|\n",
            "| Jane|  Marketing| 29000|         1|\n",
            "| Jeff|  Marketing| 35000|         2|\n",
            "| Lisa|      Sales| 10000|         1|\n",
            "| Alex|      Sales| 30000|         2|\n",
            "| Evan|      Sales| 32000|         3|\n",
            "+-----+-----------+------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# calculate dense_rank on salary\n",
        "qry1 = \"\"\"SELECT name, dept, salary, DENSE_RANK() OVER (PARTITION BY dept ORDER BY salary ROWS BETWEEN\n",
        "    UNBOUNDED PRECEDING AND CURRENT ROW) AS dense_rank FROM employees;\"\"\"\n",
        "\n",
        "spark.sql(qry1).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mE58WtSzRsg9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ab0f57-12b6-4dce-af6f-e3adcb7c33ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+------+-----+\n",
            "| name|       dept|salary|  min|\n",
            "+-----+-----------+------+-----+\n",
            "| Fred|Engineering| 21000|21000|\n",
            "|  Tom|Engineering| 23000|21000|\n",
            "|Chloe|Engineering| 23000|21000|\n",
            "| Paul|Engineering| 29000|21000|\n",
            "| Jane|  Marketing| 29000|29000|\n",
            "| Jeff|  Marketing| 35000|29000|\n",
            "| Lisa|      Sales| 10000|10000|\n",
            "| Alex|      Sales| 30000|10000|\n",
            "| Evan|      Sales| 32000|10000|\n",
            "+-----+-----------+------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# calculate min salary by dept\n",
        "qry2 = \"\"\"SELECT name, dept, salary, MIN(salary) OVER (PARTITION BY dept ORDER BY salary) AS min\n",
        "    FROM employees;\"\"\"\n",
        "\n",
        "spark.sql(qry2).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FBohSBV4Sfkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cd651ab-513f-4931-a797-ef7e16bf9976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+------+---+-----+\n",
            "| name|       dept|salary|age|  min|\n",
            "+-----+-----------+------+---+-----+\n",
            "| Fred|Engineering| 21000| 28|21000|\n",
            "|  Tom|Engineering| 23000| 33|21000|\n",
            "|Chloe|Engineering| 23000| 25|21000|\n",
            "| Paul|Engineering| 29000| 23|21000|\n",
            "| Jane|  Marketing| 29000| 28|29000|\n",
            "| Jeff|  Marketing| 35000| 38|29000|\n",
            "| Lisa|      Sales| 10000| 35|10000|\n",
            "| Alex|      Sales| 30000| 33|10000|\n",
            "| Evan|      Sales| 32000| 38|10000|\n",
            "+-----+-----------+------+---+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# same logic but using dataframes\n",
        "from pyspark.sql.functions import min\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "df = spark.table(\"employees\")\n",
        "windowSpec = Window.partitionBy(\"dept\").orderBy(\"salary\")\n",
        "df.withColumn(\"min\", min(\"salary\").over(windowSpec)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KnCXs19UXDw"
      },
      "source": [
        "# Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM33rISwSybn"
      },
      "outputs": [],
      "source": [
        "# Q1\n",
        "# Use windows functions to identify the higher salary by dept\n",
        "# Create new column \"highest_salary_dept\" and assign TRUE/FALSE accordingly\n",
        "# Identify the high salary of the company (including all the dept)\n",
        "# Create new column \"highest_salary_company\" and assign TRUE/FALSE accordingly"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZZr5pieoph-Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}